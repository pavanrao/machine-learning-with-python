{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2 Supervised Learning\n",
    "This notebook contains notes and examples from chapter 2 from the book:\n",
    "### An Introduction to Machine Learning with Python by Andreas C. Müller and Sarah Guido (O’Reilly). \n",
    "Copyright 2017 Sarah Guido and Andreas Müller, 978-1-449-36941-5.\n",
    "\n",
    "\n",
    "Supervised learning is used whenever we want to predict a certain outcome from a given input, and we have examples of input/output pairs\n",
    "\n",
    "Two major types of supervised machine learning problems:\n",
    "\n",
    "### classification \n",
    "predict a class label, which is a choice from a predefined list of possibilities\n",
    "- binary classification -  exactly two classes - yes/no\n",
    "- multiclass classification - which is classification between more than two classes.\n",
    "\n",
    "### regression\n",
    "predict a continuous number - a floating-point number or real number\n",
    "\n",
    "\n",
    "_If there is continuity between possible outcomes, then the problem is a regression problem._\n",
    "\n",
    "\n",
    "\n",
    "If a model is able to make accurate predictions on unseen data, we say it is able to **generalize** from the training set to the test set. \n",
    "\n",
    "Building a model that is too complex for the amount of information we have is called **overfitting**. Overfitting occurs when you fit a model too closely to the particularities of the training set and obtain a model that works well on the training set but is not able to generalize to new data.\n",
    "\n",
    "On the other hand, if your model is too simple,then you might not be able to capture all the aspects of and variability in the data, and your model will do badly even on the training set. Choosing too simple a model is called **underfitting**.\n",
    "\n",
    "The more complex we allow our model to be, the better we will be able to predict on the training data. However, if our model becomes too complex, we start focusing too much on each individual data point in our training set, and the model will not **generalize** well to new data. There is a sweet spot in between that will yield the best generalization performance. This is the model we want to find."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('venv': venv)",
   "language": "python",
   "name": "python38264bitvenvvenv59e1614fb8274abfaa856195f1a16cec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
